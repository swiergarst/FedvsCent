{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2411f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.stats import powerlaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05e587",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2721edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels into numbers (0 for no AML, 1 for AML)\n",
    "def convert(x):\n",
    "    if x == \"CONTROL\":\n",
    "        return 0\n",
    "    elif x == \"CASE\":\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cc9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input files\n",
    "data_A1 = pd.read_csv(\"../datasets/AML_base/dataset_A1_RMA.txt\", sep=\"\\t\")\n",
    "annotation_A1 = pd.read_csv(\"../datasets/AML_base/dataset_A1_annotation.txt\", sep=\"\\t\")\n",
    "\n",
    "data_A2 = pd.read_csv(\"../datasets/AML_base/dataset_A2_RMA.txt\", sep=\"\\t\")\n",
    "annotation_A2 = pd.read_csv(\"../datasets/AML_base/dataset_A2_annotation.txt\", sep=\"\\t\")\n",
    "\n",
    "data_A3 = pd.read_csv(\"../datasets/AML_base/dataset_A3_DESeq2.txt\", sep=\"\\t\")\n",
    "annotation_A3 = pd.read_csv(\"../datasets/AML_base/dataset_A3_annotation.txt\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# flip datafile, as the samples are columns in the original file\n",
    "data_A1 = data_A1.transpose()\n",
    "data_A2 = data_A2.transpose()\n",
    "data_A3 = data_A3.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f65a4",
   "metadata": {},
   "source": [
    "## Preprocessing on the A1-A3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6febb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the \"condition\" column, these are our labels\n",
    "labels_A1 = annotation_A1[\"Condition\"]\n",
    "labels_A2 = annotation_A2[\"Condition\"]\n",
    "labels_A3 = annotation_A3[\"Condition\"]\n",
    "\n",
    "#data_cols = data_A1.columns\n",
    "# add labels to data\n",
    "data_A1[\"label\"] = labels_A1\n",
    "data_A2[\"label\"] = labels_A2\n",
    "data_A3[\"label\"] = labels_A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10ee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data so labels are shuffled\n",
    "data_A1 = data_A1.sample(frac=1).reset_index(drop=True)\n",
    "data_A2 = data_A2.sample(frac=1).reset_index(drop=True)\n",
    "data_A3 = data_A3.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# convert labels into 0 and 1 (see function at the top)\n",
    "data_A1[\"label\"] = data_A1[\"label\"].apply(convert)\n",
    "data_A2[\"label\"] = data_A2[\"label\"].apply(convert)\n",
    "data_A3[\"label\"] = data_A3[\"label\"].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1f6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train/test split of 80/20; we'll simply annotate the top 80% as train, and then shuffle again\n",
    "full_sample_size = data_A1.shape[0]\n",
    "train_sample_size = math.floor(full_sample_size * 0.8)\n",
    "test_sample_size = full_sample_size - train_sample_size\n",
    "\n",
    "data_A1.loc[0:train_sample_size, \"test/train\"] = \"train\"\n",
    "data_A1.loc[train_sample_size:full_sample_size, \"test/train\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c137f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for A2\n",
    "full_sample_size = data_A2.shape[0]\n",
    "train_sample_size = math.floor(full_sample_size * 0.8)\n",
    "test_sample_size = full_sample_size - train_sample_size\n",
    "\n",
    "data_A2.loc[0:train_sample_size, \"test/train\"] = \"train\"\n",
    "data_A2.loc[train_sample_size:full_sample_size, \"test/train\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "599e8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for A3\n",
    "full_sample_size = data_A3.shape[0]\n",
    "train_sample_size = math.floor(full_sample_size * 0.8)\n",
    "test_sample_size = full_sample_size - train_sample_size\n",
    "\n",
    "data_A3.loc[0:train_sample_size, \"test/train\"] = \"train\"\n",
    "data_A3.loc[train_sample_size:full_sample_size, \"test/train\"] = \"test\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65120e",
   "metadata": {},
   "source": [
    "### To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86557197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e49817f",
   "metadata": {},
   "source": [
    "## Separation of A2 dataset (IID, CI, SI, 10 clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beb2cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 10 datasets\n",
    "\n",
    "# shuffle before splitting up into parts\n",
    "data_A2 = data_A2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "num_samples = data_A2.shape[0]\n",
    "num_clients = 10\n",
    "IID_sets = []\n",
    "\n",
    "samples_per_client = math.floor(num_samples/num_clients)\n",
    "for i in range(num_clients):\n",
    "    client = data_A2.iloc[i * samples_per_client:(i+1) * samples_per_client]\n",
    "    IID_sets.append(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5916647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 10 more datasets, this time sample-imbalanced\n",
    "### create uniform datasets\n",
    "num_clients = 10\n",
    "\n",
    "data_A2 = data_A2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "num_samples = data_A2.shape[0]\n",
    "# create power-law distribution\n",
    "x = np.linspace(0.1, 1.0, 10)\n",
    "pdf = np.array(powerlaw.pdf(x, a=1.66))\n",
    "pdf_norm = pdf / pdf.sum()\n",
    "# sample according to power law\n",
    "sample_nonIID_sets = []\n",
    "begin_client_samples = 0\n",
    "for i in range (num_clients):\n",
    "    client_sample_amount = math.floor(pdf_norm[i] * num_samples)\n",
    "    client = data_A2.iloc[begin_client_samples : begin_client_samples + client_sample_amount]\n",
    "    begin_client_samples += client_sample_amount\n",
    "    sample_nonIID_sets.append(client)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f66698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create non-uniform datasets, class-wise\n",
    "# split dataset in two for easier working\n",
    "A2_0 = data_A2.loc[(data_A2['label'] == 0)]\n",
    "A2_1 = data_A2.loc[(data_A2['label'] == 1)]\n",
    "\n",
    "num_clients = 10\n",
    "#shuffle both for good measure\n",
    "A2_0 = A2_0.sample(frac=1).reset_index(drop=True)\n",
    "A2_1 = A2_1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "total_samples_0 = A2_0.shape[0]\n",
    "total_samples_1 = A2_1.shape[0]\n",
    "\n",
    "class_nonIID_sets = []\n",
    "begin_sample_0 = 0\n",
    "begin_sample_1 = 0\n",
    "for i in range(num_clients):\n",
    "    amount_class_0 = math.floor(pdf_norm[i] * total_samples_0)\n",
    "    amount_class_1 = math.floor(num_samples / 10) - amount_class_0\n",
    "    tmp1 = A2_0.iloc[begin_sample_0:begin_sample_0+amount_class_0]\n",
    "    tmp2 = A2_1.iloc[begin_sample_1:begin_sample_1+amount_class_1]\n",
    "    client = pd.concat([tmp1, tmp2])\n",
    "    client = client.sample(frac=1).reset_index(drop=True)\n",
    "    class_nonIID_sets.append(client)\n",
    "    begin_sample_0 += amount_class_0\n",
    "    begin_sample_1 += amount_class_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a3c7f",
   "metadata": {},
   "source": [
    "### To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to csv's\n",
    "for i, client in enumerate(IID_sets):\n",
    "    client.to_csv(\"AML_A2_IID_client\" + str(i) + \".csv\", index=False)\n",
    "    \n",
    "# writing to csv's\n",
    "for i, client in enumerate(sample_nonIID_sets):\n",
    "    client.to_csv(\"AML_A2_PCA_client\" + str(i) + \".csv\", index=False)\n",
    "\n",
    "for i, client in enumerate(class_nonIID_sets):\n",
    "    client.to_csv(\"A2_class_imbalance_client\" + str(i) + \".csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
